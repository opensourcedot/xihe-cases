{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN生成漫画头像\n",
    "\n",
    "在下面的教程中，我们将通过示例代码说明DCGAN网络如何设置网络、优化器、如何计算损失函数以及如何初始化模型权重。在本教程中，使用的[动漫头像数据集](https://download.mindspore.cn/dataset/Faces/faces.zip)共有70,171张动漫头像图片，图片大小均为96\\*96。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN基础原理\n",
    "\n",
    "这部分原理介绍参考[GAN图像生成](https://www.mindspore.cn/tutorials/application/zh-CN/r2.5.0/generative/gan.html#模型简介)。\n",
    "\n",
    "## DCGAN原理\n",
    "\n",
    "DCGAN（深度卷积对抗生成网络，Deep Convolutional Generative Adversarial Networks）是GAN的直接扩展。不同之处在于，DCGAN会分别在判别器和生成器中使用卷积和转置卷积层。\n",
    "\n",
    "它最早由Radford等人在论文[Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434.pdf)中进行描述。判别器由分层的卷积层、BatchNorm层和LeakyReLU激活层组成。输入是3x64x64的图像，输出是该图像为真图像的概率。生成器则是由转置卷积层、BatchNorm层和ReLU激活层组成。输入是标准正态分布中提取出的隐向量$z$，输出是3x64x64的RGB图像。\n",
    "\n",
    "本教程将使用动漫头像数据集来训练一个生成式对抗网络，接着使用该网络生成动漫头像图片。\n",
    "\n",
    "## 数据准备与处理\n",
    "\n",
    "首先我们将数据集下载到指定目录下并解压。示例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# 实验环境已经预装了mindspore==2.5.0，如需更换mindspore版本，可更改下面 MINDSPORE_VERSION 变量\n",
    "!pip uninstall mindspore -y\n",
    "%env MINDSPORE_VERSION=2.5.0\n",
    "!pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/${MINDSPORE_VERSION}/MindSpore/unified/aarch64/mindspore-${MINDSPORE_VERSION}-cp39-cp39-linux_aarch64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mindspore\n",
      "Version: 2.5.0\n",
      "Summary: MindSpore is a new open source deep learning training/inference framework that could be used for mobile, edge and cloud scenarios.\n",
      "Home-page: https://www.mindspore.cn\n",
      "Author: The MindSpore Authors\n",
      "Author-email: contact@mindspore.cn\n",
      "License: Apache 2.0\n",
      "Location: /home/mindspore/miniconda/envs/jupyter/lib/python3.9/site-packages\n",
      "Requires: asttokens, astunparse, dill, numpy, packaging, pillow, protobuf, psutil, safetensors, scipy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# 查看当前 mindspore 版本\n",
    "!pip show mindspore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GLOG_v=3\n"
     ]
    }
   ],
   "source": [
    "# 控制日志的级别, 0-DEBUG、1-INFO、2-WARNING、3-ERROR\n",
    "%env GLOG_v=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://download-mindspore.osinfra.cn/dataset/Faces/faces.zip (274.6 MB)\n",
      "\n",
      "file_sizes: 100%|█████████████████████████████| 288M/288M [00:01<00:00, 234MB/s]\n",
      "Extracting zip file...\n",
      "Successfully downloaded / unzipped to ./faces\n"
     ]
    }
   ],
   "source": [
    "from download import download\n",
    "\n",
    "url = \"https://download.mindspore.cn/dataset/Faces/faces.zip\"\n",
    "\n",
    "path = download(url, \"./faces\", kind=\"zip\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "下载后的数据集目录结构如下：\n",
    "\n",
    "```text\n",
    "./faces/faces\n",
    "├── 0.jpg\n",
    "├── 1.jpg\n",
    "├── 2.jpg\n",
    "├── 3.jpg\n",
    "├── 4.jpg\n",
    "    ...\n",
    "├── 70169.jpg\n",
    "└── 70170.jpg\n",
    "```\n",
    "\n",
    "### 数据处理\n",
    "\n",
    "首先为执行过程定义一些输入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128          # 批量大小\n",
    "image_size = 64           # 训练图像空间大小\n",
    "nc = 3                    # 图像彩色通道数\n",
    "nz = 100                  # 隐向量的长度\n",
    "ngf = 64                  # 特征图在生成器中的大小\n",
    "ndf = 64                  # 特征图在判别器中的大小\n",
    "num_epochs = 3           # 训练周期数\n",
    "lr = 0.0002               # 学习率\n",
    "beta1 = 0.5               # Adam优化器的beta1超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义`create_dataset_imagenet`函数对数据进行处理和增强操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mindspore/miniconda/envs/jupyter/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/mindspore/miniconda/envs/jupyter/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/mindspore/miniconda/envs/jupyter/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/mindspore/miniconda/envs/jupyter/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.vision as vision\n",
    "\n",
    "def create_dataset_imagenet(dataset_path):\n",
    "    \"\"\"数据加载\"\"\"\n",
    "    dataset = ds.ImageFolderDataset(dataset_path,\n",
    "                                    num_parallel_workers=4,\n",
    "                                    shuffle=True,\n",
    "                                    decode=True)\n",
    "\n",
    "    # 数据增强操作\n",
    "    transforms = [\n",
    "        vision.Resize(image_size),\n",
    "        vision.CenterCrop(image_size),\n",
    "        vision.HWC2CHW(),\n",
    "        lambda x: ((x / 255).astype(\"float32\"))\n",
    "    ]\n",
    "\n",
    "    # 数据映射操作\n",
    "    dataset = dataset.project('image')\n",
    "    dataset = dataset.map(transforms, 'image')\n",
    "\n",
    "    # 批量操作\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "dataset = create_dataset_imagenet('./faces')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过`create_dict_iterator`函数将数据转换成字典迭代器，然后使用`matplotlib`模块可视化部分训练数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data(data):\n",
    "    # 可视化部分训练数据\n",
    "    plt.figure(figsize=(10, 3), dpi=140)\n",
    "    for i, image in enumerate(data[0][:30], 1):\n",
    "        plt.subplot(3, 10, i)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image.transpose(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "sample_data = next(dataset.create_tuple_iterator(output_numpy=True))\n",
    "plot_data(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造网络\n",
    "\n",
    "当处理完数据后，就可以来进行网络的搭建了。按照DCGAN论文中的描述，所有模型权重均应从`mean`为0，`sigma`为0.02的正态分布中随机初始化。\n",
    "\n",
    "### 生成器\n",
    "\n",
    "生成器`G`的功能是将隐向量`z`映射到数据空间。由于数据是图像，这一过程也会创建与真实图像大小相同的 RGB 图像。在实践场景中，该功能是通过一系列`Conv2dTranspose`转置卷积层来完成的，每个层都与`BatchNorm2d`层和`ReLu`激活层配对，输出数据会经过`tanh`函数，使其返回`[-1,1]`的数据范围内。\n",
    "\n",
    "DCGAN论文生成图像如下所示：\n",
    "\n",
    "![dcgangenerator](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.5.0/tutorials/source_zh_cn/cv/images/dcgan.png)\n",
    "\n",
    "> 图片来源：[Unsupervised Representation Learning With Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434.pdf).\n",
    "\n",
    "我们通过输入部分中设置的`nz`、`ngf`和`nc`来影响代码中的生成器结构。`nz`是隐向量`z`的长度，`ngf`与通过生成器传播的特征图的大小有关，`nc`是输出图像中的通道数。\n",
    "\n",
    "以下是生成器的代码实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "from mindspore import nn, ops\n",
    "from mindspore.common.initializer import Normal\n",
    "\n",
    "weight_init = Normal(mean=0, sigma=0.02)\n",
    "gamma_init = Normal(mean=1, sigma=0.02)\n",
    "\n",
    "class Generator(nn.Cell):\n",
    "    \"\"\"DCGAN网络生成器\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.generator = nn.SequentialCell(\n",
    "            nn.Conv2dTranspose(nz, ngf * 8, 4, 1, 'valid', weight_init=weight_init),\n",
    "            nn.BatchNorm2d(ngf * 8, gamma_init=gamma_init),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2dTranspose(ngf * 8, ngf * 4, 4, 2, 'pad', 1, weight_init=weight_init),\n",
    "            nn.BatchNorm2d(ngf * 4, gamma_init=gamma_init),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2dTranspose(ngf * 4, ngf * 2, 4, 2, 'pad', 1, weight_init=weight_init),\n",
    "            nn.BatchNorm2d(ngf * 2, gamma_init=gamma_init),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2dTranspose(ngf * 2, ngf, 4, 2, 'pad', 1, weight_init=weight_init),\n",
    "            nn.BatchNorm2d(ngf, gamma_init=gamma_init),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2dTranspose(ngf, nc, 4, 2, 'pad', 1, weight_init=weight_init),\n",
    "            nn.Tanh()\n",
    "            )\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.generator(x)\n",
    "\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 判别器\n",
    "\n",
    "如前所述，判别器`D`是一个二分类网络模型，输出判定该图像为真实图的概率。通过一系列的`Conv2d`、`BatchNorm2d`和`LeakyReLU`层对其进行处理，最后通过`Sigmoid`激活函数得到最终概率。\n",
    "\n",
    "DCGAN论文提到，使用卷积而不是通过池化来进行下采样是一个好方法，因为它可以让网络学习自己的池化特征。\n",
    "\n",
    "判别器的代码实现如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Cell):\n",
    "    \"\"\"DCGAN网络判别器\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.discriminator = nn.SequentialCell(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 'pad', 1, weight_init=weight_init),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 'pad', 1, weight_init=weight_init),\n",
    "            nn.BatchNorm2d(ngf * 2, gamma_init=gamma_init),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 'pad', 1, weight_init=weight_init),\n",
    "            nn.BatchNorm2d(ngf * 4, gamma_init=gamma_init),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 'pad', 1, weight_init=weight_init),\n",
    "            nn.BatchNorm2d(ngf * 8, gamma_init=gamma_init),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 'valid', weight_init=weight_init),\n",
    "            )\n",
    "        self.adv_layer = nn.Sigmoid()\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.discriminator(x)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        return self.adv_layer(out)\n",
    "\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "### 损失函数\n",
    "\n",
    "当定义了`D`和`G`后，接下来将使用MindSpore中定义的二进制交叉熵损失函数[BCELoss](https://www.mindspore.cn/docs/zh-CN/r2.5.0/api_python/nn/mindspore.nn.BCELoss.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "adversarial_loss = nn.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器\n",
    "\n",
    "这里设置了两个单独的优化器，一个用于`D`，另一个用于`G`。这两个都是`lr = 0.0002`和`beta1 = 0.5`的Adam优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 为生成器和判别器设置优化器\n",
    "optimizer_D = nn.Adam(discriminator.trainable_params(), learning_rate=lr, beta1=beta1)\n",
    "optimizer_G = nn.Adam(generator.trainable_params(), learning_rate=lr, beta1=beta1)\n",
    "optimizer_G.update_parameters_name('optim_g.')\n",
    "optimizer_D.update_parameters_name('optim_d.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型\n",
    "\n",
    "训练分为两个主要部分：训练判别器和训练生成器。\n",
    "\n",
    "- 训练判别器\n",
    "\n",
    "    训练判别器的目的是最大程度地提高判别图像真伪的概率。按照Goodfellow的方法，是希望通过提高其随机梯度来更新判别器，所以我们要最大化$log D(x) + log(1 - D(G(z))$的值。\n",
    "\n",
    "- 训练生成器\n",
    "\n",
    "    如DCGAN论文所述，我们希望通过最小化$log(1 - D(G(z)))$来训练生成器，以产生更好的虚假图像。\n",
    "\n",
    "在这两个部分中，分别获取训练过程中的损失，并在每个周期结束时进行统计，将`fixed_noise`批量推送到生成器中，以直观地跟踪`G`的训练进度。\n",
    "\n",
    "下面实现模型训练正向逻辑："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generator_forward(real_imgs, valid):\n",
    "    # 将噪声采样为发生器的输入\n",
    "    z = ops.standard_normal((real_imgs.shape[0], nz, 1, 1))\n",
    "\n",
    "    # 生成一批图像\n",
    "    gen_imgs = generator(z)\n",
    "\n",
    "    # 损失衡量发生器绕过判别器的能力\n",
    "    g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "    return g_loss, gen_imgs\n",
    "\n",
    "def discriminator_forward(real_imgs, gen_imgs, valid, fake):\n",
    "    # 衡量鉴别器从生成的样本中对真实样本进行分类的能力\n",
    "    real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "    fake_loss = adversarial_loss(discriminator(gen_imgs), fake)\n",
    "    d_loss = (real_loss + fake_loss) / 2\n",
    "    return d_loss\n",
    "\n",
    "grad_generator_fn = ms.value_and_grad(generator_forward, None,\n",
    "                                      optimizer_G.parameters,\n",
    "                                      has_aux=True)\n",
    "grad_discriminator_fn = ms.value_and_grad(discriminator_forward, None,\n",
    "                                          optimizer_D.parameters)\n",
    "\n",
    "@ms.jit\n",
    "def train_step(imgs):\n",
    "    valid = ops.ones((imgs.shape[0], 1), mindspore.float32)\n",
    "    fake = ops.zeros((imgs.shape[0], 1), mindspore.float32)\n",
    "\n",
    "    (g_loss, gen_imgs), g_grads = grad_generator_fn(imgs, valid)\n",
    "    optimizer_G(g_grads)\n",
    "    d_loss, d_grads = grad_discriminator_fn(imgs, gen_imgs, valid, fake)\n",
    "    optimizer_D(d_grads)\n",
    "\n",
    "    return g_loss, d_loss, gen_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "循环训练网络，每经过50次迭代，就收集生成器和判别器的损失，以便于后面绘制训练过程中损失函数的图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import mindspore\n",
    "\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "image_list = []\n",
    "\n",
    "total = dataset.get_dataset_size()\n",
    "for epoch in range(num_epochs):\n",
    "    generator.set_train()\n",
    "    discriminator.set_train()\n",
    "    # 为每轮训练读入数据\n",
    "    for i, (imgs, ) in enumerate(dataset.create_tuple_iterator()):\n",
    "        g_loss, d_loss, gen_imgs = train_step(imgs)\n",
    "        if i % 100 == 0 or i == total - 1:\n",
    "            # 输出训练记录\n",
    "            print('[%2d/%d][%3d/%d]   Loss_D:%7.4f  Loss_G:%7.4f' % (\n",
    "                epoch + 1, num_epochs, i + 1, total, d_loss.asnumpy(), g_loss.asnumpy()))\n",
    "        D_losses.append(d_loss.asnumpy())\n",
    "        G_losses.append(g_loss.asnumpy())\n",
    "\n",
    "    # 每个epoch结束后，使用生成器生成一组图片\n",
    "    generator.set_train(False)\n",
    "    fixed_noise = ops.standard_normal((batch_size, nz, 1, 1))\n",
    "    img = generator(fixed_noise)\n",
    "    image_list.append(img.transpose(0, 2, 3, 1).asnumpy())\n",
    "\n",
    "    # 保存网络模型参数为ckpt文件\n",
    "    mindspore.save_checkpoint(generator, \"./generator.ckpt\")\n",
    "    mindspore.save_checkpoint(discriminator, \"./discriminator.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果展示\n",
    "\n",
    "运行下面代码，描绘`D`和`G`损失与训练迭代的关系图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"G\", color='blue')\n",
    "plt.plot(D_losses, label=\"D\", color='orange')\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化训练过程中通过隐向量`fixed_noise`生成的图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def showGif(image_list):\n",
    "    show_list = []\n",
    "    fig = plt.figure(figsize=(8, 3), dpi=120)\n",
    "    for epoch in range(len(image_list)):\n",
    "        images = []\n",
    "        for i in range(3):\n",
    "            row = np.concatenate((image_list[epoch][i * 8:(i + 1) * 8]), axis=1)\n",
    "            images.append(row)\n",
    "        img = np.clip(np.concatenate((images[:]), axis=0), 0, 1)\n",
    "        plt.axis(\"off\")\n",
    "        show_list.append([plt.imshow(img)])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, show_list, interval=1000, repeat_delay=1000, blit=True)\n",
    "    ani.save('./dcgan.gif', writer='pillow', fps=1)\n",
    "\n",
    "showGif(image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dcgan](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.5.0/tutorials/source_zh_cn/cv/images/dcgan.gif)\n",
    "\n",
    "从上面的图像可以看出，随着训练次数的增多，图像质量也越来越好。如果增大训练周期数，当`num_epochs`达到50以上时，生成的动漫头像图片与数据集中的较为相似，下面我们通过加载生成器网络模型参数文件来生成图像，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 从文件中获取模型参数并加载到网络中\n",
    "mindspore.load_checkpoint(\"./generator.ckpt\", generator)\n",
    "\n",
    "fixed_noise = ops.standard_normal((batch_size, nz, 1, 1))\n",
    "img64 = generator(fixed_noise).transpose(0, 2, 3, 1).asnumpy()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3), dpi=120)\n",
    "images = []\n",
    "for i in range(3):\n",
    "    images.append(np.concatenate((img64[i * 8:(i + 1) * 8]), axis=1))\n",
    "img = np.clip(np.concatenate((images[:]), axis=0), 0, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 2025-02-23 05:47:06.856586\n",
    "print(datetime.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1b7d0cf718d96af9afce6b8a158fe6c40f94b7eaa199e9db8a682b64f9545fc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
